{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/proj/inductive-bias.shadow/abakalov.anaconda/envs/sae/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [01:35<00:00, 31.82s/it]\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-2b into HookedTransformer\n",
      "blocks.13.attn.hook_z\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE\n",
    "import torch\n",
    "from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# get model\n",
    "model = HookedTransformer.from_pretrained(\"google/gemma-2-2b\", device = device)\n",
    "\n",
    "layer = 13\n",
    "\n",
    "# get the SAE for this layer\n",
    "sae, cfg_dict, _ = SAE.from_pretrained(\n",
    "    release = \"gemma-scope-2b-pt-att-canonical\",\n",
    "    sae_id = f\"layer_{layer}/width_16k/canonical\",\n",
    "    device = device\n",
    ")\n",
    "\n",
    "# get hook point\n",
    "hook_point = sae.cfg.hook_name\n",
    "print(hook_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4502\n",
      "500 264\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset \n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"allenai/ai2_arc\", \"ARC-Easy\",\n",
    "    split=\"train\",\n",
    "    streaming=False,\n",
    ")\n",
    "\n",
    "def format_examples(examples) -> dict[str, list]:\n",
    "    examples_formatted = {\"sent\": [],\n",
    "                          \"label\": []}\n",
    "    for example_question, example_choices, answer in zip(examples[\"question\"], examples[\"choices\"], examples[\"answerKey\"]):\n",
    "        have_correct_example, have_incorrect_example = False, False\n",
    "        for choice, label in zip(example_choices[\"text\"], example_choices[\"label\"]):\n",
    "            if label == answer and not have_correct_example:\n",
    "                examples_formatted[\"sent\"].append(example_question + \" \" + choice)\n",
    "                examples_formatted[\"label\"].append(\"True\")\n",
    "                have_correct_example = True\n",
    "            elif not have_incorrect_example:\n",
    "                examples_formatted[\"sent\"].append(example_question + \" \" + choice)\n",
    "                examples_formatted[\"label\"].append(\"False\")\n",
    "                have_incorrect_example = True\n",
    "    return examples_formatted\n",
    "\n",
    "probing_dataset = dataset.map(format_examples, batched=True, batch_size=8, remove_columns=dataset.column_names)\n",
    "\n",
    "print(len(probing_dataset))\n",
    "\n",
    "probing_dataset = probing_dataset.shuffle(seed=42).select(range(500))\n",
    "print(len(probing_dataset), len(probing_dataset.filter(lambda example: example[\"label\"] == \"True\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'False',\n",
       " 'tokens': tensor([     2,  13033,   1134,   1546,   5476,    614,    573,  17930,    576,\n",
       "            671,   4018,    675,    476,   2301,   6620,    578,   2910,   5182,\n",
       "         235336,   3178,   5601,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0]),\n",
       " 'len_of_input': tensor(21)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "def tokenize(examples, column_name, tokenizer, max_length):\n",
    "        tokenizer.padding_side = \"right\"\n",
    "        text = examples[column_name]\n",
    "        tokens = tokenizer(text, return_tensors=\"np\", padding=\"longest\", max_length=max_length)[\"input_ids\"]\n",
    "        len_of_input = np.argmax(tokens == tokenizer.pad_token_id, axis=1)\n",
    "        assert (tokens[len_of_input == 0] != tokenizer.pad_token_id).all(), (len_of_input, tokens)\n",
    "        len_of_input[len_of_input == 0] = tokens.shape[1]\n",
    "        return {\"tokens\": tokens, \"len_of_input\": len_of_input}\n",
    "\n",
    "tokenized_dataset = probing_dataset.map(\n",
    "    partial(tokenize,\n",
    "    column_name = \"sent\",\n",
    "    tokenizer = model.tokenizer,\n",
    "    max_length=sae.cfg.context_size),\n",
    "    batched=True,\n",
    "    batch_size=8,\n",
    "    num_proc=None\n",
    ")\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"tokens\", \"label\", \"len_of_input\"])\n",
    "tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.13.attn.hook_z'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.cfg.hook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:22<00:00,  2.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 8\n",
    "head = 0\n",
    "correct_activations = []\n",
    "\n",
    "dataloader = DataLoader(tokenized_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch_tokens = batch[\"tokens\"]\n",
    "        _, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
    "\n",
    "        feature_acts = cache[sae.cfg.hook_name]\n",
    "        correct_activations.append(feature_acts[np.arange(batch_tokens.shape[0]), batch[\"len_of_input\"] - 1, head, :].detach().cpu())\n",
    "        del cache\n",
    "\n",
    "correct_activations_dataset = torch.vstack(correct_activations)\n",
    "\n",
    "X = correct_activations_dataset.numpy()\n",
    "y = np.array([1 if item[\"label\"] == \"True\" else -1 for item in tokenized_dataset])\n",
    "\n",
    "X_correct = X[y == 1]\n",
    "X_incorrect = X[y == -1]\n",
    "X_difference = (X_correct.mean(axis=0) - X_incorrect.mean(axis=0))\n",
    "\n",
    "lr = LogisticRegression(penalty=\"l1\", solver=\"liblinear\").fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_difference.shape\n",
    "\n",
    "steering_vector = torch.tensor(X_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "297it [03:26,  1.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6813973063973064, 1.5318286764099942)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def steering(activations, hook, head, steering_strength, steering_vector, max_act, pos_to_intervene=[None]):\n",
    "    activations[np.arange(activations.shape[0]), pos_to_intervene, head, :] += max_act * steering_strength * steering_vector\n",
    "    return activations\n",
    "from utils.dataset import get_tokenized_arc_easy_for_testing\n",
    "steering_vector = steering_vector.to(model.cfg.device)\n",
    "    \n",
    "tokenized_dataset = get_tokenized_arc_easy_for_testing(model, sae.cfg.context_size, \"test\", batch_size)\n",
    "dataloader = DataLoader(tokenized_dataset, batch_size=batch_size, shuffle=False)\n",
    "correct = 0\n",
    "sum_logit_diff = 0\n",
    "head = 0\n",
    "with torch.no_grad():\n",
    "    for iter, batch in tqdm(enumerate(dataloader)):\n",
    "        batch_tokens = batch[\"tokens\"]\n",
    "\n",
    "        steering_hook = partial(\n",
    "            steering,\n",
    "            steering_vector=steering_vector,\n",
    "            steering_strength=100.,\n",
    "            max_act=1.,\n",
    "            head=head,\n",
    "            pos_to_intervene=[-1 for i in range(batch_tokens.shape[0])] # padding on the left\n",
    "        )\n",
    "\n",
    "        with model.hooks(fwd_hooks=[(sae.cfg.hook_name, steering_hook)]):\n",
    "            logits = model(batch_tokens, return_type=\"logits\").cpu()\n",
    "        correct_logits = [model.tokenizer.convert_tokens_to_ids(chr(ord(\"A\") + label)) for label in batch[\"correct_label\"]]\n",
    "        incorrect_logits = [\n",
    "                [\n",
    "                    model.tokenizer.convert_tokens_to_ids(chr(ord(\"A\") + label)) for label in range(num_labels) if label != correct_label\n",
    "                ]\n",
    "                for correct_label, num_labels in zip(batch[\"correct_label\"], batch[\"num_labels\"])\n",
    "            ]\n",
    "        incorrect_logits_probs = [np.array([logits[batch_i, -1, incorrect_id] for incorrect_id in incorrect_logits[batch_i]]) for batch_i in range(len(incorrect_logits))]\n",
    "        max_incorrect_logit = [incorrect_logits[batch_i][np.argmax(incorrect_logits_probs[batch_i])] for batch_i in range(len(incorrect_logits))]\n",
    "        logit_diff = [logits[batch_i, -1, correct_logits[batch_i]] - logits[batch_i, -1, max_incorrect_logit[batch_i]] for batch_i in range(len(incorrect_logits))]\n",
    "        \n",
    "        correct += (np.array(logit_diff) > 0).sum()\n",
    "        sum_logit_diff += (np.array(logit_diff)).sum()\n",
    "correct / len(tokenized_dataset), sum_logit_diff / len(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2376/2376 [00:00<00:00, 2714.60 examples/s]\n",
      "297it [03:23,  1.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7066498316498316, 2.1488056580225625)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def steering(activations, hook, head, steering_strength, steering_vector, max_act, pos_to_intervene=[None]):\n",
    "    activations[np.arange(activations.shape[0]), pos_to_intervene, head, :] += max_act * steering_strength * steering_vector\n",
    "    return activations\n",
    "from utils.dataset import get_tokenized_arc_easy_for_testing\n",
    "steering_vector = torch.zeros(256).to(model.cfg.device)\n",
    "    \n",
    "tokenized_dataset = get_tokenized_arc_easy_for_testing(model, sae.cfg.context_size, \"test\", batch_size)\n",
    "dataloader = DataLoader(tokenized_dataset, batch_size=batch_size, shuffle=False)\n",
    "correct = 0\n",
    "sum_logit_diff = 0\n",
    "head = 0\n",
    "with torch.no_grad():\n",
    "    for iter, batch in tqdm(enumerate(dataloader)):\n",
    "        batch_tokens = batch[\"tokens\"]\n",
    "\n",
    "        steering_hook = partial(\n",
    "            steering,\n",
    "            steering_vector=steering_vector,\n",
    "            steering_strength=1.,\n",
    "            max_act=1.,\n",
    "            head=head,\n",
    "            pos_to_intervene=[-1 for i in range(batch_tokens.shape[0])] # padding on the left\n",
    "        )\n",
    "\n",
    "        with model.hooks(fwd_hooks=[(sae.cfg.hook_name, steering_hook)]):\n",
    "            logits = model(batch_tokens, return_type=\"logits\").cpu()\n",
    "        correct_logits = [model.tokenizer.convert_tokens_to_ids(chr(ord(\"A\") + label)) for label in batch[\"correct_label\"]]\n",
    "        incorrect_logits = [\n",
    "                [\n",
    "                    model.tokenizer.convert_tokens_to_ids(chr(ord(\"A\") + label)) for label in range(num_labels) if label != correct_label\n",
    "                ]\n",
    "                for correct_label, num_labels in zip(batch[\"correct_label\"], batch[\"num_labels\"])\n",
    "            ]\n",
    "        incorrect_logits_probs = [np.array([logits[batch_i, -1, incorrect_id] for incorrect_id in incorrect_logits[batch_i]]) for batch_i in range(len(incorrect_logits))]\n",
    "        max_incorrect_logit = [incorrect_logits[batch_i][np.argmax(incorrect_logits_probs[batch_i])] for batch_i in range(len(incorrect_logits))]\n",
    "        logit_diff = [logits[batch_i, -1, correct_logits[batch_i]] - logits[batch_i, -1, max_incorrect_logit[batch_i]] for batch_i in range(len(incorrect_logits))]\n",
    "        \n",
    "        correct += (np.array(logit_diff) > 0).sum()\n",
    "        sum_logit_diff += (np.array(logit_diff)).sum()\n",
    "correct / len(tokenized_dataset), sum_logit_diff / len(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength:1 (0.7070707070707071, 2.160504623494967)\n",
    ": 0 0.7066498316498316, 2.1488056580225625)\n",
    "10: (0.718013468013468, 2.201320888819518)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
