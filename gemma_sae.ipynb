{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/proj/inductive-bias.shadow/abakalov.anaconda/envs/sae/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.36s/it]\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# get model\n",
    "model = HookedTransformer.from_pretrained(\"google/gemma-2-2b\", device = device)\n",
    "\n",
    "# layer = 13\n",
    "\n",
    "# # get the SAE for this layer\n",
    "# sae, cfg_dict, _ = SAE.from_pretrained(\n",
    "#     release = \"gemma-scope-2b-pt-att-canonical\",\n",
    "#     sae_id = f\"layer_{layer}/width_16k/canonical\",\n",
    "#     device = device\n",
    "# )\n",
    "\n",
    "# # get hook point\n",
    "# hook_point = sae.cfg.hook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "with open(\"cache/accuracies_sorted_gemma.json\", \"r\") as file:\n",
    "    accuracies_sorted = json.load(file)\n",
    "\n",
    "accuracies_by_layer = {layer: np.mean([p[0] for p in accuracies_sorted if p[1] == layer]) for layer in range(26)}\n",
    "accuracies_by_layer_sorted = sorted([[acc, l] for l, acc in accuracies_by_layer.items()])\n",
    "\n",
    "k = 1\n",
    "alpha = 10\n",
    "# with open(\"cache/steering_directions.json\", \"r\") as file:\n",
    "#     steering_directions_json = json.load(file)\n",
    "# steering_directions = {}\n",
    "# for item in steering_directions_json:\n",
    "#     steering_directions[eval(item)] = np.array(steering_directions_json[item])\n",
    "# with open(\"cache/stds.json\", \"r\") as file:\n",
    "#     stds_json = json.load(file)\n",
    "# stds = {}\n",
    "# for item in stds_json:\n",
    "#     stds[eval(item)] = stds_json[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 409/409 [01:20<00:00,  5.06it/s]\n",
      "100%|██████████| 1/1 [01:21<00:00, 81.88s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import tasks.truthfulqa\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "from sae_lens import SAE\n",
    "\n",
    "steering_directions = []\n",
    "stds = []\n",
    "hook_names = []\n",
    "\n",
    "task = tasks.truthfulqa.TruthfulQA(\"probing\")\n",
    "tokenized_dataset = task.get_tokenized_dataset(tokenizer=model.tokenizer, batch_size=2, subset=False,\n",
    "                                                random_seed=42, subset_len=81, max_length=1000)\n",
    "\n",
    "layers = [l for a, l in accuracies_by_layer_sorted[:k]]\n",
    "\n",
    "for layer in tqdm(layers):\n",
    "    sae, cfg_dict, _ = SAE.from_pretrained(\n",
    "        release = \"gemma-scope-2b-pt-att-canonical\",\n",
    "        sae_id = f\"layer_{layer}/width_16k/canonical\",\n",
    "        device = device\n",
    "    )\n",
    "\n",
    "    hook_point = sae.cfg.hook_name\n",
    "    hook_names.append(hook_point)\n",
    "    sae.eval()\n",
    "    correct_activations = []\n",
    "\n",
    "    dataloader = DataLoader(tokenized_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            batch_tokens = batch[\"tokens\"]\n",
    "            _, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
    "\n",
    "            feature_acts = sae.encode(cache[sae.cfg.hook_name])\n",
    "            correct_activations.append(feature_acts[np.arange(batch_tokens.shape[0]), batch[\"len_of_input\"] - 1, :].detach().cpu())\n",
    "            del cache\n",
    "\n",
    "    correct_activations_dataset = torch.vstack(correct_activations)\n",
    "    X = correct_activations_dataset.numpy()\n",
    "    y = np.array([1 if item[\"label\"] == \"True\" else -1 for item in tokenized_dataset])\n",
    "    X_correct = X[y == 1]\n",
    "    X_incorrect = X[y == -1]\n",
    "    steering_direction = (X_correct.mean(axis=0) - X_incorrect.mean(axis=0))\n",
    "    direction_norm = np.linalg.norm(steering_direction)\n",
    "    std = np.std(np.dot(X, steering_direction) / direction_norm)\n",
    "    steering_directions.append(steering_direction)\n",
    "    stds.append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 16381, 16382, 16383])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.indices(steering_directions[0].shape)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   36,  1050,  1418,  1777,  2577,  3036,  3360,  3466,  4421,\n",
       "        4473,  4783,  4956,  5504,  5568,  6027,  6406,  7218,  7464,\n",
       "        7686,  8702,  9055, 11123, 11691, 12773, 13009, 13235, 13411,\n",
       "       13831, 14368, 14855, 15948, 15974])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.indices(steering_directions[0].shape)[0][np.abs(steering_directions[0]) > 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3194 (16384,)\n"
     ]
    }
   ],
   "source": [
    "steering_directions_in_attn_space = []\n",
    "for direction in steering_directions:\n",
    "    print(np.count_nonzero(direction), direction.shape)\n",
    "    steering_directions_in_attn_space.append(direction @ sae.W_dec.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"cache/steering_directions_gemma_sae_full.json\", \"w\") as file:\n",
    "    json.dump({str(layer): direction.tolist() for layer, direction in zip(layers, steering_directions_in_attn_space)}, file)\n",
    "with open(\"cache/stds_gemma_sae_full.json\", \"w\") as file:\n",
    "    json.dump({str(layer): std.item() for layer, std in zip(layers, stds)}, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
